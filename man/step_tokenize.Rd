% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize.R
\name{step_tokenize}
\alias{step_tokenize}
\title{Tokenization of character variables}
\usage{
step_tokenize(recipe, ..., role = NA, trained = FALSE,
  columns = NULL, skip = FALSE)
}
\arguments{
\item{recipe}{A recipe object. The step will be added to the
sequence of operations for this recipe.}

\item{...}{One or more selector functions to choose variables.
For `step_tokenize`, this indicates the variables to be encoded
into a list column. See [recipes::selections()] for more details. For
the `tidy` method, these are not currently used.}

\item{role}{Not used by this step since no new variables are
created.}

\item{trained}{A logical to indicate if the recipe has been baked.}

\item{columns}{A list of tibble results that define the
encoding. This is `NULL` until the step is trained by
[recipes::prep.recipe()].}

\item{skip}{A logical. Should the step be skipped when the
recipe is baked by [recipes::bake.recipe()]? While all operations are baked
when [recipes::prep.recipe()] is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using `skip = TRUE` as it may affect
the computations for subsequent operations}
}
\value{
An updated version of `recipe` with the new step added
 to the sequence of existing steps (if any).
}
\description{
`step_tokenize` creates a *specification* of a recipe step that
 will convert a character predictor into a list of its tokenized parts.
}
\concept{preprocessing encoding}
\keyword{datagen}
