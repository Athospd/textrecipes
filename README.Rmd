---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# textrecipes

[![Travis build status](https://travis-ci.org/EmilHvitfeldt/textrecipes.svg?branch=master)](https://travis-ci.org/EmilHvitfeldt/textrecipes)
[![Coverage status](https://codecov.io/gh/EmilHvitfeldt/textrecipes/branch/master/graph/badge.svg)](https://codecov.io/github/EmilHvitfeldt/textrecipes?branch=master)
[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/textrecipes)](http://cran.r-project.org/web/packages/textrecipes)
[![Downloads](http://cranlogs.r-pkg.org/badges/textrecipes)](http://cran.rstudio.com/package=textrecipes)
[![lifecycle](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)

**textrecipes** contains extra steps for the [`recipes`](http://cran.rstudio.com/package=recipes) package for preprocessing text data. 

## Installation

textrecipes is not avaliable from [CRAN](https://CRAN.R-project.org) yet. But the development version can be downloaded with: 

```{r installation, eval=FALSE}
require("devtools")
install_github("emilhvitfeldt/textrecipes")
```

## Example

In the following example we will go through the steps needed to convert a character variable to the TF-IDF of its tokenized words after removing stopwords and limeting ourself to only the 500 most used words. We will be conduction this preprosession on the variable `essay0`.

```{r}
library(recipes)
library(textrecipes)
 
data(okc_text)

example_data <- okc_text[, 1]

okc_rec <- recipe(~ ., data = example_data) %>%
  step_tokenize(essay0) %>% # Tokenizes to words by default
  step_stopwords(essay0) %>% # Uses the english snowball list by default
  step_tokenfilter(essay0, max.words = 500) %>%
  step_tfidf(essay0, tf.weight = "term frequency", idf.weight = "idf")
   
okc_obj <- okc_rec %>%
  prep(training = example_data, retain = TRUE)
   
bake(okc_obj, example_data)
```


## Type chart

**textrecipes** includes a little departure in design from **recipes** in the sense that it allows some input and output to be in the form of list columns. To avoind confusion here is a table of steps with their expected input and output respectively. Notice how you need to end with numeric for future analysis to work.

| Step               | Input       | Output      | Status  |
|--------------------|-------------|-------------|---------|
| `step_tokenize`    | character   | list-column | working |
| `step_untokenize`  | list-column | character   | working |
| `step_stem`        | list-column | list-column | working |
| `step_stopwords`   | list-column | list-column | working |
| `step_tokenfilter` | list-column | list-column | working |
| `step_tfidf`       | list-column | numeric     | working |
| `step_tf`          | list-column | numeric     | working |
| `step_texthash`    | list-column | numeric     | working |
| `step_word2vec`    | character   | numeric     | TODO    |

(TODO = Yet to be implemented, bug = correnctly not working, working = the step works but still not finished i.e. missing document/tests/arguemnts, done = finished)

This means that valid sequences includes

```{r, eval=FALSE}
recipe(~ ., data = data) %>%
  step_tokenize(text) %>%
  step_stem(text) %>%
  step_stopwords(text) %>%
  step_topwords(text) %>%
  step_tfidf(text)

# or

recipe(~ ., data = data) %>%
  step_tokenize(text) %>%
  step_stem(text) %>%
  step_tfidf(text)

# or

recipe(~ ., data = data) %>%
  step_word2vec(text)
```

